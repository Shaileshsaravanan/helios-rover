<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Transfer Learning - TensorFlow.js</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
  </head>
  <body class="bg-gray-50 text-gray-800 min-h-screen flex flex-col items-center justify-center">
    <div class="container mx-auto p-4 sm:p-8">
      <h1 class="text-3xl sm:text-4xl font-bold mb-6 text-center">Transfer Learning with TensorFlow.js</h1>
      <p id="status" class="text-lg text-center mb-4">Awaiting TF.js load</p>
      <div class="flex justify-center mb-6">
        <video id="webcam" class="bg-black rounded-md" autoplay muted></video>
      </div>
      <div class="grid grid-cols-2 sm:grid-cols-3 gap-4">
        <button id="enableCam" class="btn">Enable Webcam</button>
        <button class="btn dataCollector" data-1hot="0" data-name="Class 1">Gather Class 1 Data</button>
        <button class="btn dataCollector" data-1hot="1" data-name="Class 2">Gather Class 2 Data</button>
        <button id="train" class="btn col-span-2 sm:col-span-1">Train & Predict!</button>
        <button id="reset" class="btn col-span-2 sm:col-span-1">Reset</button>
      </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js"></script>
    <script type="module" src="/script.js"></script>
  </body>
</html>

<style>
  .btn {
    @apply px-4 py-2 bg-blue-500 text-white rounded-md hover:bg-blue-600 transition duration-200;
  }
  video {
    width: 100%;
    max-width: 640px;
    height: auto;
    aspect-ratio: 4/3;
  }
</style>

<script type="module">
  import * as tf from '@tensorflow/tfjs';

  const STATUS = document.getElementById('status');
  const VIDEO = document.getElementById('webcam');
  const ENABLE_CAM_BUTTON = document.getElementById('enableCam');
  const TRAIN_BUTTON = document.getElementById('train');
  const RESET_BUTTON = document.getElementById('reset');
  const MOBILE_NET_INPUT_WIDTH = 224;
  const MOBILE_NET_INPUT_HEIGHT = 224;
  const STOP_DATA_GATHER = -1;
  const CLASS_NAMES = [];

  ENABLE_CAM_BUTTON.addEventListener('click', enableCam);
  TRAIN_BUTTON.addEventListener('click', trainAndPredict);
  RESET_BUTTON.addEventListener('click', reset);

  document.querySelectorAll('button.dataCollector').forEach(button => {
    button.addEventListener('mousedown', gatherDataForClass);
    button.addEventListener('mouseup', gatherDataForClass);
    CLASS_NAMES.push(button.getAttribute('data-name'));
  });

  let mobilenet;
  let gatherDataState = STOP_DATA_GATHER;
  let videoPlaying = false;
  let trainingDataInputs = [];
  let trainingDataOutputs = [];
  let examplesCount = [];
  let predict = false;

  async function loadMobileNetFeatureModel() {
    const URL = 'https://tfhub.dev/google/tfjs-model/imagenet/mobilenet_v3_small_100_224/feature_vector/5/default/1';
    mobilenet = await tf.loadGraphModel(URL, { fromTFHub: true });
    STATUS.innerText = 'MobileNet v3 loaded successfully!';
    tf.tidy(() => mobilenet.predict(tf.zeros([1, MOBILE_NET_INPUT_HEIGHT, MOBILE_NET_INPUT_WIDTH, 3])));
  }

  loadMobileNetFeatureModel();

  async function enableCam() {
    if (videoPlaying) return;
    STATUS.innerText = 'Enabling webcam...';
    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
    VIDEO.srcObject = stream;
    VIDEO.onloadedmetadata = () => {
      VIDEO.play();
      videoPlaying = true;
      STATUS.innerText = 'Webcam enabled.';
    };
  }

  function gatherDataForClass(event) {
    gatherDataState = (event.type === 'mousedown') ? parseInt(this.getAttribute('data-1hot')) : STOP_DATA_GATHER;
    if (videoPlaying && gatherDataState !== STOP_DATA_GATHER) gatherData();
  }

  function gatherData() {
    if (!mobilenet) return;
    const videoFrame = tf.browser.fromPixels(VIDEO).toFloat().resizeBilinear([MOBILE_NET_INPUT_WIDTH, MOBILE_NET_INPUT_HEIGHT]).expandDims();
    const features = mobilenet.predict(videoFrame).flatten();
    trainingDataInputs.push(features);
    trainingDataOutputs.push(gatherDataState);
    examplesCount[gatherDataState] = (examplesCount[gatherDataState] || 0) + 1;
    STATUS.innerText = `Gathering data for ${CLASS_NAMES[gatherDataState]} (${examplesCount[gatherDataState]} examples)`;
  }

  async function trainAndPredict() {
    if (!mobilenet) return;
    STATUS.innerText = 'Training the model...';
    const xs = tf.stack(trainingDataInputs);
    const ys = tf.oneHot(tf.tensor1d(trainingDataOutputs).toInt(), CLASS_NAMES.length);
    const model = tf.sequential();
    model.add(tf.layers.dense({ inputShape: [xs.shape[1]], units: CLASS_NAMES.length, activation: 'softmax' }));
    model.compile({ optimizer: 'adam', loss: 'categoricalCrossentropy', metrics: ['accuracy'] });
    await model.fit(xs, ys, { epochs: 10 });
    predict = true;
    STATUS.innerText = 'Model trained. Ready for predictions.';
    startPredicting(model);
  }

  async function startPredicting(model) {
    while (predict) {
      const videoFrame = tf.browser.fromPixels(VIDEO).toFloat().resizeBilinear([MOBILE_NET_INPUT_WIDTH, MOBILE_NET_INPUT_HEIGHT]).expandDims();
      const features = mobilenet.predict(videoFrame).flatten();
      const predictions = model.predict(features.expandDims()).dataSync();
      const topPrediction = tf.argMax(predictions).dataSync()[0];
      STATUS.innerText = `Prediction: ${CLASS_NAMES[topPrediction]}`;
      await new Promise(requestAnimationFrame);
    }
  }

  function reset() {
    STATUS.innerText = 'Resetting...';
    trainingDataInputs = [];
    trainingDataOutputs = [];
    examplesCount = [];
    predict = false;
    gatherDataState = STOP_DATA_GATHER;
    STATUS.innerText = 'Reset complete. Collect new data.';
  }
</script>